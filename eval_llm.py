
import argparse
from pathlib import Path
import os
import pdb
import glob
# import logging
import torch
import json
import tqdm
import re
import math
import pandas as pd
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from torch.utils.data import DataLoader
from numbers import Real

from engine import local_trainer

from datasets import load_dataset, load_from_disk, concatenate_datasets
from src.data import collate_fn, collate_fn_llm
from src.utils import get_ndcg

def get_args_parser():
    parser = argparse.ArgumentParser('Deformable DETR Detector', add_help=False)
    parser.add_argument('--batch_size', default=256, type=int)
    parser.add_argument('--n_gpus', default=4, type=int,
                        help="Number of GPUs available")
    
    parser.add_argument('--save_fname', default=None, type=str)

    # dataset parameters
    parser.add_argument('--output_path', default='/home/ec2-user/workspace/cf_ranking/outputs/',
                        help='path where to save, empty for no saving')
    parser.add_argument('--data_path', default='/home/ec2-user/workspace/data/custom_click/',
                        help='path where to save, empty for no saving')
    parser.add_argument('--data_path_org', 
                        default='/ubc/cs/home/g/gbhatt/borg/ranking/data/esci-data/query_group_input_esci.jsonl')
    parser.add_argument('--output_folder', default='demo',
                        help='path where to save, empty for no saving')
    parser.add_argument('--out_file', default='demo',
                        help='file generated by LLM')
    parser.add_argument('--load_path', default='',
                        help='path where to load model')
    parser.add_argument('--device', default='cuda',
                        help='device to use for training / testing')
    parser.add_argument('--problem_type', default='classification', 
                        choices=['classification','regression'])
    parser.add_argument('--ultr_models', default=None, 
                        choices=['ips','twotower'])
    parser.add_argument('--max_positions_PE', default=50, type=int)
    parser.add_argument('--per_item_feats', action='store_true')
    parser.add_argument('--concat_feats', action='store_true')
    parser.add_argument('--use_model_preds', default=1, type=int)
    parser.add_argument('--eval_llm', action='store_true')
    parser.add_argument('--debug', action='store_true')
    parser.add_argument('--lau_eval', action='store_true')
    parser.add_argument('--choice2', action='store_true')
    parser.add_argument('--train_ranker', action='store_true')
    parser.add_argument('--pretrain_ranker', action='store_true')
    parser.add_argument('--use_doc_feat', action='store_true')
    parser.add_argument('--eval', action='store_true')
    parser.add_argument('--eval_ultr', action='store_true')
    parser.add_argument('--purchase_prob', action='store_true')
    parser.add_argument('--lr', default=2e-5, type=float)
    parser.add_argument('--weight_decay', default=1e-2, type=float)
    parser.add_argument('--train_ranker_naive', action='store_true')
    parser.add_argument('--reward_loss_type', default='mse', 
                        choices=['l1','mse','focal_l1','focal_mse','bce','fbce'])
    parser.add_argument('--load_path_reward', default='',
                        help='path where to load model')
    parser.add_argument('--num_workers', default=4, type=int)
    parser.add_argument('--lin_pos', action='store_true')
    parser.add_argument('--eval_online', action='store_true', help='generate the data for online LLM evaluation')
    parser.add_argument('--eval_offline', action='store_true', help='offline evvaluation from the inference of the LLM')

    return parser

def parse_inp(input_path, filename):
    
    prob_patterns = [
        r"P\(purchase\)\s*=\s*([\d.]+)",
        r"Final Probability[:\s*\*]*([\d.]+)"
    ]
    item_patterns = [
        r"Item to be purchased\s*=\s*(.+)",
        r"Recommended item\s*[-:>\s]*(.+)"
    ]
    
    combined_rows = []

    with open(input_path, "r") as infile:
        for line_num, line in enumerate(infile):
            record = json.loads(line)

            # Extract user input
            model_input = record.get("modelInput", {})
            messages = model_input.get("messages", [])
            input_text = ""
            query = None
            products = None

            for msg in messages:
                if msg.get("role") == "user":
                    for content_piece in msg.get("content", []):
                        if content_piece.get("type") == "text":
                            content = content_piece["text"]
                            input_text += content

                            # Extract query and products JSON
                            query_match = re.search(r'"query"\s*:\s*"([^"]+)"', content)
                            query_id_match = re.search(r'"query_id"\s*:\s*"([^"]+)"', content)
                            if query_match and query_id_match:
                                query = query_match.group(1)
                                query_id = query_id_match.group(1)

                            products_match = re.search(r'"products"\s*:\s*({.*?})\s*}', content, re.DOTALL)
                            if products_match:
                                products_json_str = products_match.group(1) + "}"
                                products = json.loads(products_json_str)
            # Extract model output
            model_output = record.get("modelOutput", {})
            output_parts = model_output.get("content", [])
            output_text = ""
            for part in output_parts:
                if part.get("type") == "text":
                    output_text += part["text"]

            # Extract fields
            probability = None
            for pattern in prob_patterns:
                match = re.search(pattern, output_text)
                if match:
                    try:
                        probability = float(match.group(1).strip())
                        break
                    except ValueError:
                        continue

            item_selected = None
            for pattern in item_patterns:
                match = re.search(pattern, output_text)
                if match:
                    raw_item = match.group(1).strip()
                    id_match = re.search(r'\b([A-Z0-9]{8,15})\b', raw_item)
                    if id_match:
                        item_selected = id_match.group(1)
                        break

            try:
                assert query
                assert products
                assert probability
                assert item_selected
                
                product_keys = list(products.keys())
                item_position = product_keys.index(item_selected)
                
                combined_rows.append({
                    "source_file": filename,
                    "query": query,
                    "products": json.dumps(products),
                    "purchase_prob": probability,
                    "item_selected": item_selected,
                    "query_id":query_id,
                    "item_position": item_position,
                    "output":output_text,
                    "input":input_text,
                })
            except:
                print(f"[{filename} Line {line_num}] Skipped: missing values")
    print (f'Processed files:{len(combined_rows)} skipped :{line_num - len(combined_rows)}')
    return pd.DataFrame(combined_rows)

def parse_inp_binary(input_path, filename):
    """
    Parses a JSONL output file to extract query, products, model predictions, and metadata.

    Args:
        input_path (str): Path to the input .jsonl.out file.

    Returns:
        pd.DataFrame: Parsed rows including query, products, prediction, and selected item info.
    """
    prob_patterns = [
        r"Output:\s*D\(purchase\)\s*=\s*(yes|no|[01](?:\.\d+)?)",
        r"\bD\(purchase\)\s*=\s*(yes|no|[01](?:\.\d+)?)",
        r"Final\s*Probability\s*[:\-\s*\)]*\s*([01](?:\.\d+)?)"
    ]

    item_patterns = [
        r"Item\s*to\s*be\s*purchased\s*=\s*[\"'“”‘’]?(?P<item>.+?)[\"'“”‘’]?(?:\s*$|\n)",
        r"Recommended\s*item\s*[-:>\s]*[\"'“”‘’]?(?P<item>.+?)[\"'“”‘’]?(?:\s*$|\n)"
    ]

    combined_rows = []

    log_file = open('/ubc/cs/home/g/gbhatt/borg/ranking/CF_ranking'+'/out.log','w')

    with open(input_path, "r") as infile:
        for line_num, line in enumerate(infile):
            record = json.loads(line)

            model_input = record.get("modelInput", {})
            messages = model_input.get("messages", [])
            input_text = ""
            query = None
            products = None

            # Extract query and products from user message
            for msg in messages:
                if msg.get("role") == "user":
                    for content_piece in msg.get("content", []):
                        if content_piece.get("type") == "text":
                            content = content_piece["text"]
                            input_text += content

                            # query_match = re.search(r'"query"\s*:\s*"([^"]+)"', content)
                            # query_id_match = re.search(r'"query_id"\s*:\s*(\d+)', content)

                            # if query_match:
                            #     query = query_match.group(1)
                            # if query_id_match:
                            #     query_id = int(query_id_match.group(1))

                            # products_match = re.search(r'"products"\s*:\s*({.*?})\s*}', content, re.DOTALL)
                            # if products_match:
                            #     products_json_str = products_match.group(1) + "}"
                            #     products = json.loads(products_json_str)

                            m = re.search(r'Your query_products shopping list:\s*(\{.*?\})\s*\n', content, re.DOTALL)
                            if m:
                                data = json.loads(m.group(1))
                                query_id = int(data["query_id"])
                                query = data['query']
                                products = data['products']

            # Extract output text from model
            model_output = record.get("modelOutput", {})
            output_parts = model_output.get("content", [])
            output_text = ""
            for part in output_parts:
                if part.get("type") == "text":
                    output_text += part["text"]

            # Extract purchase probability
            decision = None
            for pattern in prob_patterns:
                match = re.search(pattern, output_text)
                if match:
                    try:
                        decision = match.group(1).strip()
                        if decision in ['no', 'No', 'NO']:
                            decision = 0.0
                        else:
                            decision = 1.0
                        break
                    except ValueError:
                        continue

            # Extract selected item
            item_selected = None
            if decision:
                for pattern in item_patterns:
                    match = re.search(pattern, output_text)
                    if match:
                        raw_item = match.group(1).strip()
                        if raw_item:
                            id_match = re.findall(r'\b[A-Z0-9]{10}\b', raw_item)
                            if len(id_match)>0:
                                item_selected = id_match[0]
                            else:
                                for pid, pdata in products.items():
                                    #if alnum_only(raw_item.lower()) in alnum_only(pdata['product_title'].strip().lower()):
                                    if raw_item.lower() in pdata['product_title'].strip().lower():
                                        item_selected = pid
                                        break

            #pdb.set_trace()

            try:
                # --- required fields ---
                if not query:
                    raise ValueError("empty query")
                if not isinstance(products, dict) or not products:
                    raise ValueError("products must be a non-empty dict")

                # --- decision: exactly 0.0 or 1.0 (reject bool/NaN/others) ---
                if isinstance(decision, bool) or not isinstance(decision, Real):
                    raise ValueError(f"decision must be numeric 0.0 or 1.0, got {type(decision).__name__}={decision!r}")
                decision = float(decision)
                if math.isnan(decision) or decision not in (0.0, 1.0):
                    raise ValueError(f"decision must be exactly 0.0 or 1.0, got {decision!r}")

                # # --- when decision==1.0, item_selected must exist and be in products ---
                # if decision == 1.0:
                #     if not item_selected:
                #         raise ValueError("item_selected is required when decision == 1.0")
                #     if item_selected not in products:
                #         raise ValueError(f"item_selected {item_selected!r} not found in products")

                # compute position (only meaningful if item_selected provided and present)
                product_keys = list(products.keys())
                item_position = product_keys.index(item_selected) if item_selected in product_keys else -1

                combined_rows.append({
                    "source_file": filename,
                    "query": query,
                    "products": json.dumps(products, ensure_ascii=False),
                    "purchase_prob": decision,         # 0.0 or 1.0
                    "item_selected": item_selected,    # may be None/"" when decision==0.0
                    "query_id": query_id,
                    "item_position": item_position
                })

            except Exception as e:
                msg = f"[{filename} Line {line_num}] Skipped: {e}"
                print(msg)
                print(msg, file=log_file)

    print(f'Processed files: {len(combined_rows)} skipped: {line_num - len(combined_rows)}')
    return pd.DataFrame(combined_rows)

def reorder_products(default_order, new_order, products):
    products = json.loads(products)
    product_ids = list(products.keys())
    assert len(product_ids) == len(default_order), "Mismatch in default_order and products"
    reordered = {product_ids[i]: products[product_ids[i]] for i in new_order}
    return reordered

def run_ranker(args):
    train_files = glob.glob(os.path.join(args.data_path, '*'))
    datasets = [load_from_disk(d) for d in train_files]
    dataset = concatenate_datasets(datasets)
    
    dataset = dataset.filter(lambda example: example['query_id'] != -1)

    with open(args.data_path.replace('processed', 'split_indices.json'), "r") as f:
        data_ids = json.load(f)

    test_dataset = dataset.filter(lambda example: example['query_id'] in data_ids['test'])
    collate_fn = collate_fn_llm
    
    test_dataloader = DataLoader(test_dataset, collate_fn=collate_fn, batch_size=args.batch_size,
                                 num_workers=args.num_workers, drop_last=False)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    trainer = local_trainer(train_loader=test_dataloader,val_loader=test_dataloader,
                            test_dataset=test_dataset,args=args)
    trainer.to(device)
    
    trainer.resume(load_path=args.load_path, model='arranger')
    
    reordered_batch = []
    trainer.eval()
    qids = []

    with torch.no_grad():        
        for idx, batch in tqdm.tqdm(enumerate(test_dataloader)):
            feat = torch.tensor(batch['query_document_embedding'], dtype=torch.float).to(trainer.device)
            out_dict = trainer.arranger(inputs_embeds=feat)

            # new_positions = eval_llm(batch=batch, pred_scores=out_dict['logits'],
            #                         device=trainer.device, args=args)

            new_positions = torch.argsort(out_dict['logits'], dim=1, descending=True)

            # pdb.set_trace()

            for i in range(len(batch['query_id'])):
                
                reorder = reorder_products(
                        batch["position"][i],
                        new_positions[i],
                        batch['products'][i]
                        )
                #temp_reorder.append(reorder)
                temp = {'query_id':batch['query_id'][i],
                        'query':batch['query'][i],
                        'products':reorder,
                        }
                if batch['query'][i] not in qids:
                    reordered_batch.append(temp)
                    qids.append(batch['query'][i])
            #pdb.set_trace()
    
    output_path = f"{args.output_dir}/{args.output_folder}.jsonl.out"

    with open(output_path, "w") as f:
        for line in reordered_batch:
            entry = {"query_group_input": line}
            f.write(json.dumps(entry) + "\n")

    print(f"JSONL saved to: {output_path}")

def plot(df, outfile):

    df = df.copy()

    # Preprocessing
    df['products_dict'] = df['products'].apply(json.loads)
    df['num_candidates'] = df['products_dict'].apply(len)
    df['selected_in_candidates'] = df.apply(
        lambda row: row['item_selected'] in row['products_dict'], axis=1
    )

    def get_selected_position(row):
        try:
            product_ids = list(row['products_dict'].keys())
            if row['item_selected'] in product_ids:
                return product_ids.index(row['item_selected']) + 1
            else:
                return -1
        except:
            return -1

    df['selected_position'] = df.apply(get_selected_position, axis=1)

    fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(7, 5))

    # Plot 1: Purchase Probability
    sns.histplot(df['purchase_prob'], bins=20, kde=True, ax=axes)
    axes.set_title("Purchase Probability")
    axes.set_xlabel("Probability")
    axes.set_ylabel("Frequency")

    # Finalize
    plt.tight_layout()
    plt.savefig(outfile)
    #plt.show()

def plot_pos_freq(df, outfile):

    df = df.copy()

    # Preprocessing
    df['products_dict'] = df['products'].apply(json.loads)
    df['num_candidates'] = df['products_dict'].apply(len)
    df['selected_in_candidates'] = df.apply(
        lambda row: row['item_selected'] in row['products_dict'], axis=1
    )

    def get_selected_position(row):
        try:
            product_ids = list(row['products_dict'].keys())
            if row['item_selected'] in product_ids:
                return product_ids.index(row['item_selected']) + 1
            else:
                return -1
        except:
            return -1

    df['selected_position'] = df.apply(get_selected_position, axis=1)

    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14, 5))

    # Plot 1: Purchase Probability
    sns.histplot(df['purchase_prob'], bins=20, kde=True, ax=axes[0])
    axes[0].set_title("Purchase Probability")
    axes[0].set_xlabel("Probability")
    axes[0].set_ylabel("Frequency")

    # Plot 2: Selected Item Position
    sns.countplot(
        x='selected_position',
        data=df,
        order=sorted(df['selected_position'].unique()),
        stat="probability",
        ax=axes[1]
    )
    axes[1].set_title("Selected Item Position")
    axes[1].set_xlabel("Position (-1 = not found)")
    axes[1].set_ylabel("Relative Frequency")

    # Finalize
    plt.tight_layout()
    plt.savefig(outfile)
    #plt.show()

def get_org_arrangement(
    test_df: pd.DataFrame,
    org_df: pd.DataFrame,
    *,
    key_col: str = "query_id",
    products_col: str = "products",
    include_org_products: bool = False,
) -> pd.DataFrame:

    def to_dict_preserve(x):
        # Convert JSON string -> dict (order preserved); leave dicts as-is
        if isinstance(x, str):
            return json.loads(x)
        return x

    def order_key(d):
        if d is None or (isinstance(d, float) and pd.isna(d)):
            return None
        if not isinstance(d, dict):
            raise TypeError(f"Expected dict for products; got {type(d)}")
        # insertion order encodes the arrangement
        return tuple(d.keys())

    df_t = test_df.copy()
    df_o = org_df.copy()

    # Align dtypes for join key
    if key_col == "query_id":
        df_t[key_col] = pd.to_numeric(df_t[key_col], errors="coerce").astype("Int64")
        df_o[key_col] = pd.to_numeric(df_o[key_col], errors="coerce").astype("Int64")
    else:
        df_t[key_col] = df_t[key_col].astype(str).str.strip()
        df_o[key_col] = df_o[key_col].astype(str).str.strip()

    # Build arrangement signatures
    df_t["_prod_dict"] = df_t[products_col].apply(to_dict_preserve)
    df_o["_prod_dict"] = df_o[products_col].apply(to_dict_preserve)

    df_t["_order"] = df_t["_prod_dict"].apply(order_key)
    df_o["_order"] = df_o["_prod_dict"].apply(order_key)

    # One canonical arrangement per key from org_df
    cols = [key_col, "_order"]
    if include_org_products:
        cols.append(products_col)

    org_uni = df_o.drop_duplicates(subset=[key_col])[cols]

    #pdb.set_trace()

    # Keep ALL matching test rows (no dedupe)
    matched = df_t.merge(org_uni, on=[key_col, "_order"], how="inner", suffixes=("", "_org"))

    # Clean helper columns
    matched = matched.drop(columns=["_prod_dict", "_order"], errors="ignore")

    return matched

def prob_purchase(args):
    #inp_file = os.path.join(args.output_dir, args.out_file)

    inp_file = args.out_file
    
    llm_df = parse_inp(inp_file, inp_file)

    train_files = glob.glob(os.path.join(args.data_path, '*'))
    datasets = [load_from_disk(d) for d in train_files]
    dataset = concatenate_datasets(datasets)
    
    dataset = dataset.filter(lambda example: example['query_id'] != -1)

    with open(args.data_path.replace('processed', 'split_indices.json'), "r") as f:
        data_ids = json.load(f)

    test_dataset = dataset.filter(lambda example: example['query_id'] in data_ids['test'])
    
    test_df = test_dataset.to_pandas()

    org_df = pd.read_json(args.data_path_org, lines=True)
    org_df = pd.DataFrame(org_df["query_group_input"].tolist())

    #test_max = test_df.loc[test_df.groupby('query_id')['purchase_prob'].idxmax()]
    #llm_df_max = llm_df.loc[llm_df.groupby('query_id')['purchase_prob'].idxmax()]

    ### test_rand = test_df.groupby("query_id").apply(lambda x: x.sample(1)).reset_index(drop=True)
    ### merged = llm_df_max.merge(test_max, on='query_id', suffixes=('_df', '_test'))

    #test_max = get_org_arrangement(test_df, org_df)
    test_max = test_df.loc[test_df.groupby('query_id')['purchase_prob'].idxmin()]
    llm_df_max = llm_df

    llm_df_max['query_id'] = llm_df_max['query_id'].astype(int)
    test_max['query_id'] = test_max['query_id'].astype(int)

    # print(f"\nBefore - Expected purchase prob: E[p(pur)] = {np.mean(test_dataset['purchase_prob']):.4f}")
    # print(f"After  - Expected purchase prob: E[p(pur)] = {llm_df['purchase_prob'].mean():.4f}")

    # print(f"\nBefore - Expected purchase prob: E[p(pur)] = {np.mean(test_dataset['purchase_prob']):.4f}", file=args.log_file)
    # print(f"After  - Expected purchase prob: E[p(pur)] = {llm_df['purchase_prob'].mean():.4f}", file=args.log_file)

    #pdb.set_trace()
    
    def get_cutoff(threshold_high, threshold_low=0.0):
        test_filtered = test_max[test_max['purchase_prob'] <= threshold_high]

        if threshold_low == 0.0:
            test_filtered = test_filtered[test_filtered['purchase_prob'] >= threshold_low]
        else:
            test_filtered = test_filtered[test_filtered['purchase_prob'] > threshold_low]

        query_ids_below_thresh = test_filtered['query_id']
        df_filtered = llm_df_max[llm_df_max['query_id'].isin(query_ids_below_thresh)]

        merged = df_filtered.merge(test_filtered, on='query_id', suffixes=('_df', '_test'))
        merged['purchase_prob_diff'] = merged['purchase_prob_df'] - merged['purchase_prob_test']

        #pdb.set_trace()

        mean_before = merged['purchase_prob_test'].mean()
        mean_after = merged['purchase_prob_df'].mean()

        se_before = merged['purchase_prob_test'].std(ddof=1) / np.sqrt(len(merged))
        se_after = merged['purchase_prob_df'].std(ddof=1) / np.sqrt(len(merged))
        se_diff = merged['purchase_prob_diff'].std(ddof=1) / np.sqrt(len(merged))

        print(f"\nCut-off {threshold_low}:{threshold_high}  Before - Expected purchase prob: "
            f"E[p(pur) in {threshold_low}:{threshold_high}] = {mean_before:.4f} ± {se_before:.4f}")
        print(f"Cut-off {threshold_low}:{threshold_high}  After  - Expected purchase prob: "
            f"E[p(pur) in {threshold_low}:{threshold_high}] = {mean_after:.4f} ± {se_after:.4f}")
        print(f"Cut-off {threshold_low}:{threshold_high}  E[p(pur') - p(pur)]: "
            f"E[p(pur) in {threshold_low}:{threshold_high}] = {merged['purchase_prob_diff'].mean():.4f} ± {se_diff:.4f}\n")

        print(f"\nCut-off {threshold_low}:{threshold_high}  Before - Expected purchase prob: "
            f"E[p(pur) in {threshold_low}:{threshold_high}] = {mean_before:.4f} ± {se_before:.4f}", file=args.log_file)
        print(f"Cut-off {threshold_low}:{threshold_high}  After  - Expected purchase prob: "
            f"E[p(pur) in {threshold_low}:{threshold_high}] = {mean_after:.4f} ± {se_after:.4f}\n", file=args.log_file)

        #pdb.set_trace()

        plot(test_filtered, os.path.join(args.output_dir, 
                            f"test_{threshold_low}_{threshold_high}.jpg"))
        plot(df_filtered, os.path.join(args.output_dir, 
                            f"llm_{threshold_low}_{threshold_high}.jpg"))

    get_cutoff(1.0, 0.8)
    get_cutoff(0.8, 0.6)
    get_cutoff(0.6, 0.4)
    get_cutoff(0.4, 0.0)
    get_cutoff(1.0, 0.0)

    # plot(test_max, os.path.join(args.output_dir, 
    #                         f"test_max.jpg"))
    
    # plot(llm_df_max, os.path.join(args.output_dir, 
    #                         f"llm_max.jpg"))

def get_esci_vector(product_str, esci_labels):
    """
    Takes a JSON string of products and the esci_labels dict.
    Returns a list of mapped float values based on product_id order.
    """
    esci_map = {'E': 1.00, 'S': 0.10, 'C': 0.01, 'I': 0.00}
    product_dict = json.loads(product_str)
    product_ids = list(product_dict.keys())
    return [esci_map.get(esci_labels.get(pid, 'I'), 0.0) for pid in product_ids]

                         
def get_ndcg_esci(df):
    df['esci_vector_test'] = df.apply(lambda row: get_esci_vector(row['products_test'], row['esci_labels']), axis=1)
    df['esci_vector_llm'] = df.apply(lambda row: get_esci_vector(row['products_llm'], row['esci_labels']), axis=1)
    
    ndcg_10 = get_ndcg(torch.tensor(df['esci_vector_llm']), torch.tensor(df['esci_vector_test']))

    return ndcg_10


def prepare_purchase_ndcg(df, pad_to=0):
    """
    Prepares pred/target/mask tensors for purchase-based NDCG evaluation with asymmetric penalty/reward.

    Args:
        df: DataFrame with columns ['query_id', 'item_position_test', 'item_position_llm']
        pad_to: Pad size (max items per QG)

    Returns:
        preds_tensor, targets_tensor, mask_tensor
    """
    grouped = df.groupby('query_id')
    preds, targets, masks = [], [], []

    for qid, group in grouped:
        n = len(group)
        pad_len = pad_to - n

        test_pos = group['item_position_test'].tolist()
        llm_pos = group['item_position_llm'].tolist()

        # Infer click/purchase positions
        test_purchase = next((p for p in test_pos if p >= 0), -1)
        llm_purchase = next((p for p in llm_pos if p >= 0), -1)

        # Skip case: both -1 (no purchase in test or llm)
        if test_purchase == -1 and llm_purchase == -1:
            continue

        # One-hot vectors (if purchase exists)
        target = [0] * n
        pred = [0] * n

        if test_purchase >= 0 and test_purchase < n:
            target[test_purchase] = 1
        if llm_purchase >= 0 and llm_purchase < n:
            pred[llm_purchase] = 1

        mask = [1] * n

        # Pad
        target += [0] * pad_len
        pred += [0] * pad_len
        mask += [0] * pad_len

        preds.append(pred)
        targets.append(target)
        masks.append(mask)

    preds_tensor = torch.tensor(preds, dtype=torch.float32)
    targets_tensor = torch.tensor(targets, dtype=torch.float32)
    mask_tensor = torch.tensor(masks, dtype=torch.float32)

    return preds_tensor, targets_tensor, mask_tensor



def binary_purchase(args):
    inp_file = os.path.join(args.output_dir, args.out_file)
    
    llm_df = parse_inp_binary(inp_file, inp_file)

    train_files = glob.glob(os.path.join(args.data_path, '*'))
    datasets = [load_from_disk(d) for d in train_files]
    dataset = concatenate_datasets(datasets)
    
    dataset = dataset.filter(lambda example: example['query_id'] != -1)

    with open(args.data_path.replace('processed', 'split_indices.json'), "r") as f:
        data_ids = json.load(f)

    test_dataset = dataset.filter(lambda example: example['query_id'] in data_ids['test'])
    
    test_df = test_dataset.to_pandas()

    org_df = pd.read_json(args.data_path_org, lines=True)
    org_df = pd.DataFrame(org_df["query_group_input"].tolist())


    test_df = get_org_arrangement(test_df, org_df)

    llm_df['query_id'] = llm_df['query_id'].astype(int)
    test_df['query_id'] = test_df['query_id'].astype(int)

    merged = llm_df.merge(test_df, on='query_id', suffixes=('_llm', '_test'))
    merged_org = merged.merge(org_df, on='query_id', suffixes=('_final', '_org'))

    ndcg10_esci = get_ndcg_esci(merged_org)

    preds, targets, mask = prepare_purchase_ndcg(merged)
    ndcg5 = get_ndcg(preds=preds, targets=targets, k=5, mask=mask, gain_fn='exp', return_mean=True)
    ndcg10 = get_ndcg(preds=preds, targets=targets, k=10, mask=mask, gain_fn='exp', return_mean=True)

    merged['purchase_prob_diff'] = merged['purchase_prob_llm'] - merged['purchase_prob_test']
    se_before = merged['purchase_prob_test'].std(ddof=1) / np.sqrt(len(merged))
    se_after = merged['purchase_prob_llm'].std(ddof=1) / np.sqrt(len(merged))
    se_diff = merged['purchase_prob_diff'].std(ddof=1) / np.sqrt(len(merged))

    mean_before = merged['purchase_prob_test'].mean()
    mean_after = merged['purchase_prob_llm'].mean()

    print(f"\nBefore - Expected purchase prob: " f"E[p(pur)] = {mean_before:.4f} ± {se_before:.4f}")
    print(f"After  - Expected purchase prob: " f"E[p(pur)] = {mean_after:.4f} ± {se_after:.4f}\n")
    print(f"NDCG10-esci  = {ndcg10_esci:.4f}")
    print(f"\nNDCG_purchase@5: {ndcg5:.4f}")
    print(f"NDCG_purchase@10: {ndcg10:.4f}")


if __name__ == '__main__':
    parser = argparse.ArgumentParser('Rank BERT', parents=[get_args_parser()])
    args = parser.parse_args()
    args.output_folder = args.output_folder.replace('-', '_')
    args.output_dir = os.path.join(args.output_path,args.output_folder)
    args.log_file = open(args.output_dir+'/out_eval.log','a')
    
    if args.eval_online:
        run_ranker(args)
    else:
        if args.purchase_prob:
            prob_purchase(args)
        else:
            binary_purchase(args)