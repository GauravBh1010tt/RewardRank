Logging: args  Namespace(lr=2e-05, batch_size=512, weight_decay=0.01, epochs=25, eval_epochs=1, use_model_preds=1, print_freq=500, max_positions_PE=50, max_items_QG=21, repo_name='philipphager/baidu-ultr_uva-mlm-ctr', perturbation_sampling=False, sampling_type='rand_perturb', ultr_models='ips', lr_drop=15, save_epochs=5, delta_retain=0.5, soft_labels=False, soft_base=0.9, soft_gain=0.02, lr_drop_epochs=None, clip_max_norm=0.1, n_gpus=2, problem_type='classification', save_fname=None, output_path='/home/ec2-user/workspace/outputs/', data_path='/home/ec2-user/workspace/data/custom_click', output_folder='rr_ips_hard_pre', load_path='', load_path_reward='/home/ec2-user/workspace/outputs/ultr_ips/checkpoints/checkpoint30.pth', load_path_ranker='/home/ec2-user/workspace/outputs/ranker_ips/checkpoints/checkpoint20.pth', device='cuda', seed=42, n_viz=0, resume=0, start_epoch=0, eval=False, ste=True, concat_feats=False, pretrain_ranker=True, merge_imgs=False, train_ranker=True, train_ranker_lambda=False, eval_rels=False, force_tnse=False, use_dcg=False, save_cls=False, debug=False, use_wandb=False, use_doc_feat=True, num_workers=4, log_file=<_io.TextIOWrapper name='/home/ec2-user/workspace/outputs/rr_ips_hard_pre/out.log' mode='a' encoding='UTF-8'>, wandb_project_name='ranking', limit_train_batches=None, limit_val_batches=None, limit_test_batches=None, output_dir='/home/ec2-user/workspace/outputs/rr_ips_hard_pre')

 Resuming  reward _model from :  /home/ec2-user/workspace/outputs/ultr_ips/checkpoints/checkpoint30.pth

 Resuming  arranger _model from :  /home/ec2-user/workspace/outputs/ranker_ips/checkpoints/checkpoint20.pth

 Val acc after  0  epochs :  tensor(13.0052, device='cuda:0', dtype=torch.float64)   loss :  0.6550877112487813

 Train acc after  0  epochs :  73.303356181635   loss :  0.6463088639985222

 Val acc after  1  epochs :  tensor(12.4103, device='cuda:0', dtype=torch.float64)   loss :  0.6493397472536316

 Train acc after  1  epochs :  72.59193293033967   loss :  0.6495405437945188

 Val acc after  2  epochs :  tensor(12.5285, device='cuda:0', dtype=torch.float64)   loss :  0.6502494238767779

 Train acc after  2  epochs :  72.2152507915947   loss :  0.6508375037145505

 Val acc after  3  epochs :  tensor(12.1665, device='cuda:0', dtype=torch.float64)   loss :  0.6467858307219307

 Train acc after  3  epochs :  72.24167476252158   loss :  0.648502776310804

 Val acc after  4  epochs :  tensor(12.0471, device='cuda:0', dtype=torch.float64)   loss :  0.6464689862827387

 Train acc after  4  epochs :  72.91531735751295   loss :  0.6453361007019721

 Val acc after  5  epochs :  tensor(12.3222, device='cuda:0', dtype=torch.float64)   loss :  0.6482513863425546

 Saving at epoch  5

 Train acc after  5  epochs :  72.88034776194588   loss :  0.6459368419518217

 Val acc after  6  epochs :  tensor(12.2707, device='cuda:0', dtype=torch.float64)   loss :  0.6481662908207911

 Train acc after  6  epochs :  72.89833855066206   loss :  0.6456733706214185

 Val acc after  7  epochs :  tensor(12.1647, device='cuda:0', dtype=torch.float64)   loss :  0.6474742118922613

 Train acc after  7  epochs :  73.03360679332182   loss :  0.6452360137990328

 Val acc after  8  epochs :  tensor(12.2717, device='cuda:0', dtype=torch.float64)   loss :  0.6484757698156509

 Train acc after  8  epochs :  73.17179853914796   loss :  0.6445881033610396

 Val acc after  9  epochs :  tensor(12.0638, device='cuda:0', dtype=torch.float64)   loss :  0.6454876308515886

 Train acc after  9  epochs :  71.69880271301093   loss :  0.6513162123446141

 Val acc after  10  epochs :  tensor(12.1058, device='cuda:0', dtype=torch.float64)   loss :  0.6469297946579404

 Saving at epoch  10

 Train acc after  10  epochs :  73.26388888888889   loss :  0.6445621866640355

 Val acc after  11  epochs :  tensor(12.1009, device='cuda:0', dtype=torch.float64)   loss :  0.6467158452774494

 Train acc after  11  epochs :  72.58608592400691   loss :  0.6474216608129091
