Logging: args  Namespace(lr=2e-05, batch_size=512, weight_decay=0.01, epochs=25, eval_epochs=1, use_model_preds=1, print_freq=500, max_positions_PE=50, max_items_QG=21, repo_name='philipphager/baidu-ultr_uva-mlm-ctr', perturbation_sampling=False, sampling_type='rand_perturb', ultr_models='ips', lr_drop=20, save_epochs=5, delta_retain=0.5, soft_labels=False, soft_base=0.9, soft_gain=0.02, lr_drop_epochs=None, clip_max_norm=0.1, n_gpus=2, problem_type='classification', save_fname=None, output_path='/home/ec2-user/workspace/outputs/', data_path='/home/ec2-user/workspace/data/custom_click', output_folder='A_R_ips', load_path='', load_path_reward='/home/ec2-user/workspace/outputs/sr_df/checkpoints/checkpoint35.pth', device='cuda', seed=42, n_viz=5, resume=0, start_epoch=0, eval=False, merge_imgs=False, train_ranker=True, force_tnse=False, save_cls=True, debug=False, use_wandb=False, use_doc_feat=True, num_workers=4, log_file=<_io.TextIOWrapper name='/home/ec2-user/workspace/outputs/A_R_ips/out.log' mode='a' encoding='UTF-8'>, wandb_project_name='ranking', limit_train_batches=None, limit_val_batches=None, limit_test_batches=None, output_dir='/home/ec2-user/workspace/outputs/A_R_ips')

 Resuming  reward _model from :  /home/ec2-user/workspace/outputs/sr_df/checkpoints/checkpoint35.pth

 Val acc after  0  epochs :  tensor(18.6795, device='cuda:0', dtype=torch.float64)   loss :  0.7468751701912177

 Train acc after  0  epochs :  63.4384445164076   loss :  0.7379170622811226
Logging: args  Namespace(lr=2e-05, batch_size=512, weight_decay=0.01, epochs=25, eval_epochs=1, use_model_preds=1, print_freq=500, max_positions_PE=50, max_items_QG=21, repo_name='philipphager/baidu-ultr_uva-mlm-ctr', perturbation_sampling=False, sampling_type='rand_perturb', ultr_models='ips', lr_drop=20, save_epochs=5, delta_retain=0.5, soft_labels=False, soft_base=0.9, soft_gain=0.02, lr_drop_epochs=None, clip_max_norm=0.1, n_gpus=2, problem_type='classification', save_fname=None, output_path='/home/ec2-user/workspace/outputs/', data_path='/home/ec2-user/workspace/data/custom_click', output_folder='A_R_ips', load_path='', load_path_reward='/home/ec2-user/workspace/outputs/ips/checkpoints/checkpoint35.pth', device='cuda', seed=42, n_viz=5, resume=0, start_epoch=0, eval=False, merge_imgs=False, train_ranker=True, force_tnse=False, save_cls=True, debug=False, use_wandb=False, use_doc_feat=True, num_workers=4, log_file=<_io.TextIOWrapper name='/home/ec2-user/workspace/outputs/A_R_ips/out.log' mode='a' encoding='UTF-8'>, wandb_project_name='ranking', limit_train_batches=None, limit_val_batches=None, limit_test_batches=None, output_dir='/home/ec2-user/workspace/outputs/A_R_ips')

 Resuming  reward _model from :  /home/ec2-user/workspace/outputs/ips/checkpoints/checkpoint35.pth
Logging: args  Namespace(lr=2e-05, batch_size=512, weight_decay=0.01, epochs=25, eval_epochs=1, use_model_preds=1, print_freq=500, max_positions_PE=50, max_items_QG=21, repo_name='philipphager/baidu-ultr_uva-mlm-ctr', perturbation_sampling=False, sampling_type='rand_perturb', ultr_models='ips', lr_drop=20, save_epochs=5, delta_retain=0.5, soft_labels=False, soft_base=0.9, soft_gain=0.02, lr_drop_epochs=None, clip_max_norm=0.1, n_gpus=2, problem_type='classification', save_fname=None, output_path='/home/ec2-user/workspace/outputs/', data_path='/home/ec2-user/workspace/data/custom_click', output_folder='A_R_ips', load_path='', load_path_reward='/home/ec2-user/workspace/outputs/ultr_ips/checkpoints/checkpoint35.pth', device='cuda', seed=42, n_viz=5, resume=0, start_epoch=0, eval=False, merge_imgs=False, train_ranker=True, force_tnse=False, save_cls=True, debug=False, use_wandb=False, use_doc_feat=True, num_workers=4, log_file=<_io.TextIOWrapper name='/home/ec2-user/workspace/outputs/A_R_ips/out.log' mode='a' encoding='UTF-8'>, wandb_project_name='ranking', limit_train_batches=None, limit_val_batches=None, limit_test_batches=None, output_dir='/home/ec2-user/workspace/outputs/A_R_ips')

 Resuming  reward _model from :  /home/ec2-user/workspace/outputs/ultr_ips/checkpoints/checkpoint35.pth
Logging: args  Namespace(lr=2e-05, batch_size=512, weight_decay=0.01, epochs=25, eval_epochs=1, use_model_preds=1, print_freq=500, max_positions_PE=50, max_items_QG=21, repo_name='philipphager/baidu-ultr_uva-mlm-ctr', perturbation_sampling=False, sampling_type='rand_perturb', ultr_models='ips', lr_drop=20, save_epochs=5, delta_retain=0.5, soft_labels=False, soft_base=0.9, soft_gain=0.02, lr_drop_epochs=None, clip_max_norm=0.1, n_gpus=2, problem_type='classification', save_fname=None, output_path='/home/ec2-user/workspace/outputs/', data_path='/home/ec2-user/workspace/data/custom_click', output_folder='A_R_ips', load_path='', load_path_reward='/home/ec2-user/workspace/outputs/ultr_ips/checkpoints/checkpoint35.pth', device='cuda', seed=42, n_viz=5, resume=0, start_epoch=0, eval=False, merge_imgs=False, train_ranker=True, force_tnse=False, save_cls=True, debug=False, use_wandb=False, use_doc_feat=True, num_workers=4, log_file=<_io.TextIOWrapper name='/home/ec2-user/workspace/outputs/A_R_ips/out.log' mode='a' encoding='UTF-8'>, wandb_project_name='ranking', limit_train_batches=None, limit_val_batches=None, limit_test_batches=None, output_dir='/home/ec2-user/workspace/outputs/A_R_ips')

 Resuming  reward _model from :  /home/ec2-user/workspace/outputs/ultr_ips/checkpoints/checkpoint35.pth

 Val acc after  0  epochs :  tensor(12.6063, device='cuda:0', dtype=torch.float64)   loss :  0.6431609964905532

 Train acc after  0  epochs :  69.00322035118019   loss :  0.6385594418885094

 Val acc after  1  epochs :  tensor(12.6040, device='cuda:0', dtype=torch.float64)   loss :  0.6431224882967421

 Train acc after  1  epochs :  68.99838532671272   loss :  0.6378225544057464

 Val acc after  2  epochs :  tensor(12.6023, device='cuda:0', dtype=torch.float64)   loss :  0.6431303434648353

 Train acc after  2  epochs :  68.85670786557283   loss :  0.6379210141236675

 Val acc after  3  epochs :  tensor(12.6590, device='cuda:0', dtype=torch.float64)   loss :  0.6438042697357363

 Train acc after  3  epochs :  68.86064335060449   loss :  0.6380126806685994

 Val acc after  4  epochs :  tensor(12.6590, device='cuda:0', dtype=torch.float64)   loss :  0.6438041934485712

 Train acc after  4  epochs :  68.85468390184225   loss :  0.6383374371163972

 Val acc after  5  epochs :  tensor(12.6590, device='cuda:0', dtype=torch.float64)   loss :  0.6438037905093582

 Saving at epoch  5

 Train acc after  5  epochs :  68.84748758635578   loss :  0.638481819042642

 Val acc after  6  epochs :  tensor(12.6595, device='cuda:0', dtype=torch.float64)   loss :  0.6438023366846015

 Train acc after  6  epochs :  68.88234473949338   loss :  0.6384800264388453

 Val acc after  7  epochs :  tensor(12.6587, device='cuda:0', dtype=torch.float64)   loss :  0.6438038898081831

 Train acc after  7  epochs :  69.0329051525619   loss :  0.6381103983119467

 Val acc after  8  epochs :  tensor(12.6590, device='cuda:0', dtype=torch.float64)   loss :  0.6437997616826937

 Train acc after  8  epochs :  68.92304889896373   loss :  0.638183972231432

 Val acc after  9  epochs :  tensor(12.6586, device='cuda:0', dtype=torch.float64)   loss :  0.6437976443741275

 Train acc after  9  epochs :  68.88931617012089   loss :  0.6385519298942792

 Val acc after  10  epochs :  tensor(12.6582, device='cuda:0', dtype=torch.float64)   loss :  0.6437943528464212

 Saving at epoch  10

 Train acc after  10  epochs :  68.90876871042026   loss :  0.6382928567099565

 Val acc after  11  epochs :  tensor(12.6588, device='cuda:0', dtype=torch.float64)   loss :  0.6438038829474183

 Train acc after  11  epochs :  68.92709682642487   loss :  0.638410078109591

 Val acc after  12  epochs :  tensor(12.6589, device='cuda:0', dtype=torch.float64)   loss :  0.6438038868551201

 Train acc after  12  epochs :  68.92046272308578   loss :  0.6381268506802703

 Val acc after  13  epochs :  tensor(12.6590, device='cuda:0', dtype=torch.float64)   loss :  0.6438039648634044

 Train acc after  13  epochs :  68.84782491364422   loss :  0.6383443741374235

 Val acc after  14  epochs :  tensor(12.6590, device='cuda:0', dtype=torch.float64)   loss :  0.6438040547271972

 Train acc after  14  epochs :  68.85288482297064   loss :  0.6383662872166274

 Val acc after  15  epochs :  tensor(12.6590, device='cuda:0', dtype=torch.float64)   loss :  0.6438040611245124

 Saving at epoch  15

 Train acc after  15  epochs :  68.86379173862983   loss :  0.6383862354299862

 Val acc after  16  epochs :  tensor(12.6590, device='cuda:0', dtype=torch.float64)   loss :  0.6438040535263798

 Train acc after  16  epochs :  68.8972995826137   loss :  0.6382659964353949

 Val acc after  17  epochs :  tensor(12.6588, device='cuda:0', dtype=torch.float64)   loss :  0.6438038744775001

 Train acc after  17  epochs :  68.97690882268279   loss :  0.6383185270540209

 Val acc after  18  epochs :  tensor(12.6590, device='cuda:0', dtype=torch.float64)   loss :  0.6438040206045695

 Train acc after  18  epochs :  68.88965349740933   loss :  0.6382006826893919

 Val acc after  19  epochs :  tensor(12.6590, device='cuda:0', dtype=torch.float64)   loss :  0.6438040022112425

 Train acc after  19  epochs :  68.96420282815198   loss :  0.6381662360113692

 Val acc after  20  epochs :  tensor(12.6590, device='cuda:0', dtype=torch.float64)   loss :  0.6438040660560815

 Saving at epoch  20

 Train acc after  20  epochs :  68.91675212291307   loss :  0.6382213402343335

 Val acc after  21  epochs :  tensor(12.6590, device='cuda:0', dtype=torch.float64)   loss :  0.6438040312372142

 Train acc after  21  epochs :  68.90696963154865   loss :  0.6382232473525749

 Val acc after  22  epochs :  tensor(12.6590, device='cuda:0', dtype=torch.float64)   loss :  0.6438040162598507

 Train acc after  22  epochs :  68.93035765687968   loss :  0.6384676355309058

 Val acc after  23  epochs :  tensor(12.6590, device='cuda:0', dtype=torch.float64)   loss :  0.643804019932604

 Train acc after  23  epochs :  68.77945991652274   loss :  0.6385295352691948

 Val acc after  24  epochs :  tensor(12.6590, device='cuda:0', dtype=torch.float64)   loss :  0.6438040651937706

 Train acc after  24  epochs :  68.8568203080023   loss :  0.6385655907236051
