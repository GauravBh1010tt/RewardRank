ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 195, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 163, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 46, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 938, in _run
    self.__setup_profiler()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1071, in __setup_profiler
    self.profiler.setup(stage=self.state.fn, local_rank=local_rank, log_dir=self.log_dir)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1233, in log_dir
    dirpath = self.strategy.broadcast(dirpath)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/ddp.py", line 307, in broadcast
    torch.distributed.broadcast_object_list(obj, src, group=_group.WORLD)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2901, in broadcast_object_list
    broadcast(object_sizes_tensor, src=src, group=group)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2205, in broadcast
    work = default_pg.broadcast([tensor], opts)
torch.distributed.DistBackendError: NCCL error in: /opt/conda/conda-bld/pytorch_1724789143830/work/torch/csrc/distributed/c10d/NCCLUtils.hpp:275, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.20.5
ncclUnhandledCudaError: Call to CUDA function failed.
Last error:
Cuda failure 2 'out of memory'
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 195, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 163, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 46, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 938, in _run
    self.__setup_profiler()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1071, in __setup_profiler
    self.profiler.setup(stage=self.state.fn, local_rank=local_rank, log_dir=self.log_dir)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1233, in log_dir
    dirpath = self.strategy.broadcast(dirpath)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/ddp.py", line 307, in broadcast
    torch.distributed.broadcast_object_list(obj, src, group=_group.WORLD)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2901, in broadcast_object_list
    broadcast(object_sizes_tensor, src=src, group=group)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2205, in broadcast
    work = default_pg.broadcast([tensor], opts)
torch.distributed.DistBackendError: NCCL error in: /opt/conda/conda-bld/pytorch_1724789143830/work/torch/csrc/distributed/c10d/NCCLUtils.hpp:275, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.20.5
ncclUnhandledCudaError: Call to CUDA function failed.
Last error:
Cuda failure 2 'out of memory'
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 195, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 163, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 46, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 938, in _run
    self.__setup_profiler()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1071, in __setup_profiler
    self.profiler.setup(stage=self.state.fn, local_rank=local_rank, log_dir=self.log_dir)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1233, in log_dir
    dirpath = self.strategy.broadcast(dirpath)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/ddp.py", line 307, in broadcast
    torch.distributed.broadcast_object_list(obj, src, group=_group.WORLD)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2901, in broadcast_object_list
    broadcast(object_sizes_tensor, src=src, group=group)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2205, in broadcast
    work = default_pg.broadcast([tensor], opts)
torch.distributed.DistBackendError: NCCL error in: /opt/conda/conda-bld/pytorch_1724789143830/work/torch/csrc/distributed/c10d/NCCLUtils.hpp:275, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.20.5
ncclUnhandledCudaError: Call to CUDA function failed.
Last error:
Cuda failure 2 'out of memory'
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 195, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 163, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 46, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 938, in _run
    self.__setup_profiler()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1071, in __setup_profiler
    self.profiler.setup(stage=self.state.fn, local_rank=local_rank, log_dir=self.log_dir)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1233, in log_dir
    dirpath = self.strategy.broadcast(dirpath)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/ddp.py", line 307, in broadcast
    torch.distributed.broadcast_object_list(obj, src, group=_group.WORLD)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2901, in broadcast_object_list
    broadcast(object_sizes_tensor, src=src, group=group)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2205, in broadcast
    work = default_pg.broadcast([tensor], opts)
torch.distributed.DistBackendError: NCCL error in: /opt/conda/conda-bld/pytorch_1724789143830/work/torch/csrc/distributed/c10d/NCCLUtils.hpp:275, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.20.5
ncclUnhandledCudaError: Call to CUDA function failed.
Last error:
Cuda failure 2 'out of memory'
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 195, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 163, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 46, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 938, in _run
    self.__setup_profiler()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1071, in __setup_profiler
    self.profiler.setup(stage=self.state.fn, local_rank=local_rank, log_dir=self.log_dir)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1233, in log_dir
    dirpath = self.strategy.broadcast(dirpath)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/ddp.py", line 307, in broadcast
    torch.distributed.broadcast_object_list(obj, src, group=_group.WORLD)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2901, in broadcast_object_list
    broadcast(object_sizes_tensor, src=src, group=group)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2205, in broadcast
    work = default_pg.broadcast([tensor], opts)
torch.distributed.DistBackendError: NCCL error in: /opt/conda/conda-bld/pytorch_1724789143830/work/torch/csrc/distributed/c10d/NCCLUtils.hpp:275, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.20.5
ncclUnhandledCudaError: Call to CUDA function failed.
Last error:
Cuda failure 2 'out of memory'
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 195, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 163, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 46, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 938, in _run
    self.__setup_profiler()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1071, in __setup_profiler
    self.profiler.setup(stage=self.state.fn, local_rank=local_rank, log_dir=self.log_dir)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1233, in log_dir
    dirpath = self.strategy.broadcast(dirpath)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/ddp.py", line 307, in broadcast
    torch.distributed.broadcast_object_list(obj, src, group=_group.WORLD)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2901, in broadcast_object_list
    broadcast(object_sizes_tensor, src=src, group=group)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2205, in broadcast
    work = default_pg.broadcast([tensor], opts)
torch.distributed.DistBackendError: NCCL error in: /opt/conda/conda-bld/pytorch_1724789143830/work/torch/csrc/distributed/c10d/NCCLUtils.hpp:275, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.20.5
ncclUnhandledCudaError: Call to CUDA function failed.
Last error:
Failed to CUDA calloc async 40 bytes
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 195, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 163, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 46, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 938, in _run
    self.__setup_profiler()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1071, in __setup_profiler
    self.profiler.setup(stage=self.state.fn, local_rank=local_rank, log_dir=self.log_dir)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1233, in log_dir
    dirpath = self.strategy.broadcast(dirpath)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/ddp.py", line 307, in broadcast
    torch.distributed.broadcast_object_list(obj, src, group=_group.WORLD)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2901, in broadcast_object_list
    broadcast(object_sizes_tensor, src=src, group=group)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2205, in broadcast
    work = default_pg.broadcast([tensor], opts)
torch.distributed.DistBackendError: NCCL error in: /opt/conda/conda-bld/pytorch_1724789143830/work/torch/csrc/distributed/c10d/NCCLUtils.hpp:275, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.20.5
ncclUnhandledCudaError: Call to CUDA function failed.
Last error:
Cuda failure 2 'out of memory'
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 195, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 163, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 46, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 938, in _run
    self.__setup_profiler()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1071, in __setup_profiler
    self.profiler.setup(stage=self.state.fn, local_rank=local_rank, log_dir=self.log_dir)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1233, in log_dir
    dirpath = self.strategy.broadcast(dirpath)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/ddp.py", line 307, in broadcast
    torch.distributed.broadcast_object_list(obj, src, group=_group.WORLD)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2901, in broadcast_object_list
    broadcast(object_sizes_tensor, src=src, group=group)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2205, in broadcast
    work = default_pg.broadcast([tensor], opts)
torch.distributed.DistBackendError: NCCL error in: /opt/conda/conda-bld/pytorch_1724789143830/work/torch/csrc/distributed/c10d/NCCLUtils.hpp:275, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.20.5
ncclUnhandledCudaError: Call to CUDA function failed.
Last error:
Failed to CUDA calloc async 40 bytes
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 195, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 163, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 46, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 938, in _run
    self.__setup_profiler()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1071, in __setup_profiler
    self.profiler.setup(stage=self.state.fn, local_rank=local_rank, log_dir=self.log_dir)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1233, in log_dir
    dirpath = self.strategy.broadcast(dirpath)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/ddp.py", line 307, in broadcast
    torch.distributed.broadcast_object_list(obj, src, group=_group.WORLD)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2901, in broadcast_object_list
    broadcast(object_sizes_tensor, src=src, group=group)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2205, in broadcast
    work = default_pg.broadcast([tensor], opts)
torch.distributed.DistBackendError: NCCL error in: /opt/conda/conda-bld/pytorch_1724789143830/work/torch/csrc/distributed/c10d/NCCLUtils.hpp:275, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.20.5
ncclUnhandledCudaError: Call to CUDA function failed.
Last error:
Cuda failure 2 'out of memory'
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 195, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 163, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 46, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 938, in _run
    self.__setup_profiler()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1071, in __setup_profiler
    self.profiler.setup(stage=self.state.fn, local_rank=local_rank, log_dir=self.log_dir)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1233, in log_dir
    dirpath = self.strategy.broadcast(dirpath)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/ddp.py", line 307, in broadcast
    torch.distributed.broadcast_object_list(obj, src, group=_group.WORLD)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2901, in broadcast_object_list
    broadcast(object_sizes_tensor, src=src, group=group)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2205, in broadcast
    work = default_pg.broadcast([tensor], opts)
torch.distributed.DistBackendError: NCCL error in: /opt/conda/conda-bld/pytorch_1724789143830/work/torch/csrc/distributed/c10d/NCCLUtils.hpp:275, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.20.5
ncclUnhandledCudaError: Call to CUDA function failed.
Last error:
Cuda failure 2 'out of memory'
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 195, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 163, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 46, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 938, in _run
    self.__setup_profiler()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1071, in __setup_profiler
    self.profiler.setup(stage=self.state.fn, local_rank=local_rank, log_dir=self.log_dir)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1233, in log_dir
    dirpath = self.strategy.broadcast(dirpath)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/ddp.py", line 307, in broadcast
    torch.distributed.broadcast_object_list(obj, src, group=_group.WORLD)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2901, in broadcast_object_list
    broadcast(object_sizes_tensor, src=src, group=group)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2205, in broadcast
    work = default_pg.broadcast([tensor], opts)
torch.distributed.DistBackendError: NCCL error in: /opt/conda/conda-bld/pytorch_1724789143830/work/torch/csrc/distributed/c10d/NCCLUtils.hpp:275, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.20.5
ncclUnhandledCudaError: Call to CUDA function failed.
Last error:
Cuda failure 2 'out of memory'
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 195, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 163, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 46, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 938, in _run
    self.__setup_profiler()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1071, in __setup_profiler
    self.profiler.setup(stage=self.state.fn, local_rank=local_rank, log_dir=self.log_dir)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1233, in log_dir
    dirpath = self.strategy.broadcast(dirpath)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/ddp.py", line 307, in broadcast
    torch.distributed.broadcast_object_list(obj, src, group=_group.WORLD)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2901, in broadcast_object_list
    broadcast(object_sizes_tensor, src=src, group=group)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2205, in broadcast
    work = default_pg.broadcast([tensor], opts)
torch.distributed.DistBackendError: NCCL error in: /opt/conda/conda-bld/pytorch_1724789143830/work/torch/csrc/distributed/c10d/NCCLUtils.hpp:275, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.20.5
ncclUnhandledCudaError: Call to CUDA function failed.
Last error:
Cuda failure 2 'out of memory'
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 195, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 163, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 46, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 938, in _run
    self.__setup_profiler()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1071, in __setup_profiler
    self.profiler.setup(stage=self.state.fn, local_rank=local_rank, log_dir=self.log_dir)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1233, in log_dir
    dirpath = self.strategy.broadcast(dirpath)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/ddp.py", line 307, in broadcast
    torch.distributed.broadcast_object_list(obj, src, group=_group.WORLD)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2901, in broadcast_object_list
    broadcast(object_sizes_tensor, src=src, group=group)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2205, in broadcast
    work = default_pg.broadcast([tensor], opts)
torch.distributed.DistBackendError: NCCL error in: /opt/conda/conda-bld/pytorch_1724789143830/work/torch/csrc/distributed/c10d/NCCLUtils.hpp:275, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.20.5
ncclUnhandledCudaError: Call to CUDA function failed.
Last error:
Cuda failure 2 'out of memory'
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 195, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 163, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 46, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 938, in _run
    self.__setup_profiler()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1071, in __setup_profiler
    self.profiler.setup(stage=self.state.fn, local_rank=local_rank, log_dir=self.log_dir)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1233, in log_dir
    dirpath = self.strategy.broadcast(dirpath)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/ddp.py", line 307, in broadcast
    torch.distributed.broadcast_object_list(obj, src, group=_group.WORLD)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2901, in broadcast_object_list
    broadcast(object_sizes_tensor, src=src, group=group)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2205, in broadcast
    work = default_pg.broadcast([tensor], opts)
torch.distributed.DistBackendError: NCCL error in: /opt/conda/conda-bld/pytorch_1724789143830/work/torch/csrc/distributed/c10d/NCCLUtils.hpp:275, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.20.5
ncclUnhandledCudaError: Call to CUDA function failed.
Last error:
Cuda failure 2 'out of memory'
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 4618, in _parse_scatter_color_args
    colors = mcolors.to_rgba_array(c)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/colors.py", line 512, in to_rgba_array
    rgba = np.array([to_rgba(cc) for cc in c])
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/colors.py", line 512, in <listcomp>
    rgba = np.array([to_rgba(cc) for cc in c])
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/colors.py", line 314, in to_rgba
    rgba = _to_rgba_no_colorcycle(c, alpha)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/colors.py", line 398, in _to_rgba_no_colorcycle
    raise ValueError(f"Invalid RGBA argument: {orig_c!r}")
ValueError: Invalid RGBA argument: np.float64(0.5808604254821323)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 195, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 163, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1018, in _run_stage
    return self._evaluation_loop.run()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py", line 178, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 254, in on_run_end
    self._on_evaluation_epoch_end()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 334, in _on_evaluation_epoch_end
    call._call_lightning_module_hook(trainer, hook_name)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 167, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/ec2-user/workspace/cf_rank/engine.py", line 252, in on_validation_epoch_end
    self.evaluator.plot_tsne(dim=self.config.hidden_size, saved_params=self.save_output, val_acc=val_acc_avg)
  File "/home/ec2-user/workspace/cf_rank/engine.py", line 374, in plot_tsne
    scatter.append(i.scatter(embed[:, 0], embed[:, 1], c=j[0:n_viz].view(-1), cmap='jet', s=50, alpha=0.7))
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/__init__.py", line 1473, in inner
    return func(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 4805, in scatter
    self._parse_scatter_color_args(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 4624, in _parse_scatter_color_args
    raise invalid_shape_exception(c.size, xsize) from err
ValueError: 'c' argument has 6400 elements, which is inconsistent with 'x' and 'y' with size 320.
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 4618, in _parse_scatter_color_args
    colors = mcolors.to_rgba_array(c)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/colors.py", line 512, in to_rgba_array
    rgba = np.array([to_rgba(cc) for cc in c])
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/colors.py", line 512, in <listcomp>
    rgba = np.array([to_rgba(cc) for cc in c])
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/colors.py", line 314, in to_rgba
    rgba = _to_rgba_no_colorcycle(c, alpha)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/colors.py", line 398, in _to_rgba_no_colorcycle
    raise ValueError(f"Invalid RGBA argument: {orig_c!r}")
ValueError: Invalid RGBA argument: np.float64(0.5808604254821323)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 195, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 163, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1018, in _run_stage
    return self._evaluation_loop.run()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py", line 178, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 254, in on_run_end
    self._on_evaluation_epoch_end()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 334, in _on_evaluation_epoch_end
    call._call_lightning_module_hook(trainer, hook_name)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 167, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/ec2-user/workspace/cf_rank/engine.py", line 252, in on_validation_epoch_end
    self.evaluator.plot_tsne(dim=self.config.hidden_size, saved_params=self.save_output, val_acc=val_acc_avg)
  File "/home/ec2-user/workspace/cf_rank/engine.py", line 374, in plot_tsne
    scatter.append(i.scatter(embed[:, 0], embed[:, 1], c=j[0:n_viz].view(-1), cmap='jet', s=50, alpha=0.7))
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/__init__.py", line 1473, in inner
    return func(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 4805, in scatter
    self._parse_scatter_color_args(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 4624, in _parse_scatter_color_args
    raise invalid_shape_exception(c.size, xsize) from err
ValueError: 'c' argument has 6400 elements, which is inconsistent with 'x' and 'y' with size 320.
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 4618, in _parse_scatter_color_args
    colors = mcolors.to_rgba_array(c)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/colors.py", line 512, in to_rgba_array
    rgba = np.array([to_rgba(cc) for cc in c])
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/colors.py", line 512, in <listcomp>
    rgba = np.array([to_rgba(cc) for cc in c])
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/colors.py", line 314, in to_rgba
    rgba = _to_rgba_no_colorcycle(c, alpha)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/colors.py", line 398, in _to_rgba_no_colorcycle
    raise ValueError(f"Invalid RGBA argument: {orig_c!r}")
ValueError: Invalid RGBA argument: np.float64(0.5808604254821323)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 195, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 163, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1018, in _run_stage
    return self._evaluation_loop.run()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py", line 178, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 254, in on_run_end
    self._on_evaluation_epoch_end()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 334, in _on_evaluation_epoch_end
    call._call_lightning_module_hook(trainer, hook_name)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 167, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/ec2-user/workspace/cf_rank/engine.py", line 252, in on_validation_epoch_end
    self.evaluator.plot_tsne(dim=self.config.hidden_size, saved_params=self.save_output, val_acc=val_acc_avg)
  File "/home/ec2-user/workspace/cf_rank/engine.py", line 374, in plot_tsne
    scatter.append(i.scatter(embed[:, 0], embed[:, 1], c=j[0:n_viz].view(-1), cmap='jet', s=50, alpha=0.7))
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/__init__.py", line 1473, in inner
    return func(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 4805, in scatter
    self._parse_scatter_color_args(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 4624, in _parse_scatter_color_args
    raise invalid_shape_exception(c.size, xsize) from err
ValueError: 'c' argument has 6400 elements, which is inconsistent with 'x' and 'y' with size 320.
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 4618, in _parse_scatter_color_args
    colors = mcolors.to_rgba_array(c)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/colors.py", line 512, in to_rgba_array
    rgba = np.array([to_rgba(cc) for cc in c])
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/colors.py", line 512, in <listcomp>
    rgba = np.array([to_rgba(cc) for cc in c])
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/colors.py", line 314, in to_rgba
    rgba = _to_rgba_no_colorcycle(c, alpha)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/colors.py", line 398, in _to_rgba_no_colorcycle
    raise ValueError(f"Invalid RGBA argument: {orig_c!r}")
ValueError: Invalid RGBA argument: np.float64(0.5808604254821323)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 195, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 163, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1018, in _run_stage
    return self._evaluation_loop.run()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py", line 178, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 254, in on_run_end
    self._on_evaluation_epoch_end()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 334, in _on_evaluation_epoch_end
    call._call_lightning_module_hook(trainer, hook_name)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 167, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/ec2-user/workspace/cf_rank/engine.py", line 252, in on_validation_epoch_end
    self.evaluator.plot_tsne(dim=self.config.hidden_size, saved_params=self.save_output, val_acc=val_acc_avg)
  File "/home/ec2-user/workspace/cf_rank/engine.py", line 374, in plot_tsne
    scatter.append(i.scatter(embed[:, 0], embed[:, 1], c=j[0:n_viz].view(-1), cmap='jet', s=50, alpha=0.7))
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/__init__.py", line 1473, in inner
    return func(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 4805, in scatter
    self._parse_scatter_color_args(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/matplotlib/axes/_axes.py", line 4624, in _parse_scatter_color_args
    raise invalid_shape_exception(c.size, xsize) from err
ValueError: 'c' argument has 6400 elements, which is inconsistent with 'x' and 'y' with size 320.
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 198, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 163, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 46, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 938, in _run
    self.__setup_profiler()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1071, in __setup_profiler
    self.profiler.setup(stage=self.state.fn, local_rank=local_rank, log_dir=self.log_dir)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1233, in log_dir
    dirpath = self.strategy.broadcast(dirpath)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/ddp.py", line 307, in broadcast
    torch.distributed.broadcast_object_list(obj, src, group=_group.WORLD)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2901, in broadcast_object_list
    broadcast(object_sizes_tensor, src=src, group=group)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2205, in broadcast
    work = default_pg.broadcast([tensor], opts)
torch.distributed.DistBackendError: NCCL error in: /opt/conda/conda-bld/pytorch_1724789143830/work/torch/csrc/distributed/c10d/NCCLUtils.hpp:275, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.20.5
ncclUnhandledCudaError: Call to CUDA function failed.
Last error:
Cuda failure 2 'out of memory'
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 198, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 163, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 46, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 938, in _run
    self.__setup_profiler()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1071, in __setup_profiler
    self.profiler.setup(stage=self.state.fn, local_rank=local_rank, log_dir=self.log_dir)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1233, in log_dir
    dirpath = self.strategy.broadcast(dirpath)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/ddp.py", line 307, in broadcast
    torch.distributed.broadcast_object_list(obj, src, group=_group.WORLD)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2901, in broadcast_object_list
    broadcast(object_sizes_tensor, src=src, group=group)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2205, in broadcast
    work = default_pg.broadcast([tensor], opts)
torch.distributed.DistBackendError: NCCL error in: /opt/conda/conda-bld/pytorch_1724789143830/work/torch/csrc/distributed/c10d/NCCLUtils.hpp:275, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.20.5
ncclUnhandledCudaError: Call to CUDA function failed.
Last error:
Cuda failure 2 'out of memory'
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 198, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 163, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 46, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 938, in _run
    self.__setup_profiler()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1071, in __setup_profiler
    self.profiler.setup(stage=self.state.fn, local_rank=local_rank, log_dir=self.log_dir)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1233, in log_dir
    dirpath = self.strategy.broadcast(dirpath)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/ddp.py", line 307, in broadcast
    torch.distributed.broadcast_object_list(obj, src, group=_group.WORLD)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2901, in broadcast_object_list
    broadcast(object_sizes_tensor, src=src, group=group)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2205, in broadcast
    work = default_pg.broadcast([tensor], opts)
torch.distributed.DistBackendError: NCCL error in: /opt/conda/conda-bld/pytorch_1724789143830/work/torch/csrc/distributed/c10d/NCCLUtils.hpp:275, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.20.5
ncclUnhandledCudaError: Call to CUDA function failed.
Last error:
Cuda failure 2 'out of memory'
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 198, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 163, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 46, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 938, in _run
    self.__setup_profiler()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1071, in __setup_profiler
    self.profiler.setup(stage=self.state.fn, local_rank=local_rank, log_dir=self.log_dir)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1233, in log_dir
    dirpath = self.strategy.broadcast(dirpath)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/ddp.py", line 307, in broadcast
    torch.distributed.broadcast_object_list(obj, src, group=_group.WORLD)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2901, in broadcast_object_list
    broadcast(object_sizes_tensor, src=src, group=group)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2205, in broadcast
    work = default_pg.broadcast([tensor], opts)
torch.distributed.DistBackendError: NCCL error in: /opt/conda/conda-bld/pytorch_1724789143830/work/torch/csrc/distributed/c10d/NCCLUtils.hpp:275, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.20.5
ncclUnhandledCudaError: Call to CUDA function failed.
Last error:
Cuda failure 2 'out of memory'
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 198, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 163, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 46, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/launchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 938, in _run
    self.__setup_profiler()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1071, in __setup_profiler
    self.profiler.setup(stage=self.state.fn, local_rank=local_rank, log_dir=self.log_dir)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1233, in log_dir
    dirpath = self.strategy.broadcast(dirpath)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/ddp.py", line 307, in broadcast
    torch.distributed.broadcast_object_list(obj, src, group=_group.WORLD)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2901, in broadcast_object_list
    broadcast(object_sizes_tensor, src=src, group=group)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/c10d_logger.py", line 79, in wrapper
    return func(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/distributed/distributed_c10d.py", line 2205, in broadcast
    work = default_pg.broadcast([tensor], opts)
torch.distributed.DistBackendError: NCCL error in: /opt/conda/conda-bld/pytorch_1724789143830/work/torch/csrc/distributed/c10d/NCCLUtils.hpp:275, unhandled cuda error (run with NCCL_DEBUG=INFO for details), NCCL version 2.20.5
ncclUnhandledCudaError: Call to CUDA function failed.
Last error:
Cuda failure 2 'out of memory'
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 200, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 142, in main
    pyl_trainer = pl.Trainer(devices=list(range(args.n_gpus)), accelerator="gpu", max_epochs=args.epochs,
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 395, in __init__
    self._accelerator_connector = _AcceleratorConnector(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py", line 146, in __init__
    self._set_parallel_devices_and_init_accelerator()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py", line 376, in _set_parallel_devices_and_init_accelerator
    self._devices_flag = accelerator_cls.parse_devices(self._devices_flag)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/accelerators/cuda.py", line 88, in parse_devices
    return _parse_gpu_ids(devices, include_cuda=True)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/lightning_fabric/utilities/device_parser.py", line 102, in _parse_gpu_ids
    return _sanitize_gpu_ids(gpus, include_cuda=include_cuda, include_mps=include_mps)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/lightning_fabric/utilities/device_parser.py", line 135, in _sanitize_gpu_ids
    raise MisconfigurationException(
lightning_fabric.utilities.exceptions.MisconfigurationException: You requested gpu: [0, 1]
 But your machine only has: [0]
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 200, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 142, in main
    pyl_trainer = pl.Trainer(devices=list(range(args.n_gpus)), accelerator="gpu", max_epochs=args.epochs,
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 395, in __init__
    self._accelerator_connector = _AcceleratorConnector(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py", line 146, in __init__
    self._set_parallel_devices_and_init_accelerator()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py", line 376, in _set_parallel_devices_and_init_accelerator
    self._devices_flag = accelerator_cls.parse_devices(self._devices_flag)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/accelerators/cuda.py", line 88, in parse_devices
    return _parse_gpu_ids(devices, include_cuda=True)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/lightning_fabric/utilities/device_parser.py", line 102, in _parse_gpu_ids
    return _sanitize_gpu_ids(gpus, include_cuda=include_cuda, include_mps=include_mps)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/lightning_fabric/utilities/device_parser.py", line 135, in _sanitize_gpu_ids
    raise MisconfigurationException(
lightning_fabric.utilities.exceptions.MisconfigurationException: You requested gpu: [0, 1]
 But your machine only has: [0]
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 200, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 142, in main
    pyl_trainer = pl.Trainer(devices=list(range(args.n_gpus)), accelerator="gpu", max_epochs=args.epochs,
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/utilities/argparse.py", line 70, in insert_env_defaults
    return fn(self, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 395, in __init__
    self._accelerator_connector = _AcceleratorConnector(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py", line 146, in __init__
    self._set_parallel_devices_and_init_accelerator()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py", line 376, in _set_parallel_devices_and_init_accelerator
    self._devices_flag = accelerator_cls.parse_devices(self._devices_flag)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/accelerators/cuda.py", line 88, in parse_devices
    return _parse_gpu_ids(devices, include_cuda=True)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/lightning_fabric/utilities/device_parser.py", line 102, in _parse_gpu_ids
    return _sanitize_gpu_ids(gpus, include_cuda=include_cuda, include_mps=include_mps)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/lightning_fabric/utilities/device_parser.py", line 135, in _sanitize_gpu_ids
    raise MisconfigurationException(
lightning_fabric.utilities.exceptions.MisconfigurationException: You requested gpu: [0, 1]
 But your machine only has: [0]
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 200, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 164, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1018, in _run_stage
    return self._evaluation_loop.run()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py", line 178, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 142, in run
    return self.on_run_end()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 254, in on_run_end
    self._on_evaluation_epoch_end()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 334, in _on_evaluation_epoch_end
    call._call_lightning_module_hook(trainer, hook_name)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 167, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
  File "/home/ec2-user/workspace/cf_rank/engine.py", line 242, in on_validation_epoch_end
    val_acc_avg = defaultdict(lambda: [])
TypeError: unsupported operand type(s) for /: 'dict' and 'int'
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 200, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 164, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1018, in _run_stage
    return self._evaluation_loop.run()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py", line 178, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 319, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 411, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
  File "/home/ec2-user/workspace/cf_rank/engine.py", line 215, in validation_step
    self.val_acc[i] += distance_prob(prob1, prob2, distance_type=i)
KeyError: 'tv'
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 200, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 164, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1018, in _run_stage
    return self._evaluation_loop.run()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py", line 178, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 319, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 411, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
  File "/home/ec2-user/workspace/cf_rank/engine.py", line 215, in validation_step
    self.val_acc[i] += distance_prob(prob1, prob2, distance_type=i)
KeyError: 'tv'
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 200, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 164, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1018, in _run_stage
    return self._evaluation_loop.run()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py", line 178, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 319, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 411, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
  File "/home/ec2-user/workspace/cf_rank/engine.py", line 215, in validation_step
    self.val_acc[i] += distance_prob(prob1, prob2, distance_type=i)
KeyError: 'tv'
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 200, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 164, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1018, in _run_stage
    return self._evaluation_loop.run()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py", line 178, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 319, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 411, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
  File "/home/ec2-user/workspace/cf_rank/engine.py", line 215, in validation_step
    self.val_acc[i] += distance_prob(prob1, prob2, distance_type=i)
KeyError: 'tv'
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 200, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 164, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1018, in _run_stage
    return self._evaluation_loop.run()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py", line 178, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 319, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 411, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
  File "/home/ec2-user/workspace/cf_rank/engine.py", line 215, in validation_step
    self.val_acc[i] += distance_prob(prob1, prob2, distance_type=i)
KeyError: 'tv'
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 200, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 164, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1018, in _run_stage
    return self._evaluation_loop.run()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py", line 178, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 319, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 411, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
  File "/home/ec2-user/workspace/cf_rank/engine.py", line 215, in validation_step
    self.val_acc[i] += distance_prob(prob1, prob2, distance_type=i)
TypeError: unsupported operand type(s) for +=: 'type' and 'Tensor'
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 200, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 164, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1018, in _run_stage
    return self._evaluation_loop.run()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py", line 178, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 319, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 411, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
  File "/home/ec2-user/workspace/cf_rank/engine.py", line 215, in validation_step
    self.val_acc[i] += distance_prob(prob1, prob2, distance_type=i)
TypeError: unsupported operand type(s) for +=: 'type' and 'Tensor'
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 200, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 164, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1018, in _run_stage
    return self._evaluation_loop.run()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py", line 178, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 319, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 411, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
  File "/home/ec2-user/workspace/cf_rank/engine.py", line 215, in validation_step
    self.val_acc[i] += distance_prob(prob1, prob2, distance_type=i)
TypeError: unsupported operand type(s) for +=: 'type' and 'Tensor'
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 200, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 164, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1018, in _run_stage
    return self._evaluation_loop.run()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py", line 178, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 319, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 411, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
  File "/home/ec2-user/workspace/cf_rank/engine.py", line 215, in validation_step
    self.val_acc[i] += distance_prob(prob1, prob2, distance_type=i)
TypeError: unsupported operand type(s) for +=: 'type' and 'Tensor'
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 200, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 164, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1018, in _run_stage
    return self._evaluation_loop.run()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py", line 178, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 319, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 411, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
  File "/home/ec2-user/workspace/cf_rank/engine.py", line 215, in validation_step
    self.val_acc[i] += distance_prob(prob1, prob2, distance_type=i)
TypeError: unsupported operand type(s) for +=: 'type' and 'Tensor'
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1131, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/multiprocessing/queues.py", line 117, in get
    res = self._recv_bytes()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/multiprocessing/connection.py", line 216, in recv_bytes
    buf = self._recv_bytes(maxlength)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/multiprocessing/connection.py", line 421, in _recv_bytes
    return self._recv(size)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 67, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 78443) is killed by signal: Killed. 

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 212, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 176, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1018, in _run_stage
    return self._evaluation_loop.run()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py", line 178, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 128, in run
    batch, batch_idx, dataloader_idx = next(data_fetcher)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/fetchers.py", line 133, in __next__
    batch = super().__next__()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/fetchers.py", line 60, in __next__
    batch = next(self.iterator)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/utilities/combined_loader.py", line 341, in __next__
    out = next(self._iterator)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/utilities/combined_loader.py", line 142, in __next__
    out = next(self.iterators[0])
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1327, in _next_data
    idx, data = self._get_data()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1293, in _get_data
    success, data = self._try_get_data()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1144, in _try_get_data
    raise RuntimeError(f'DataLoader worker (pid(s) {pids_str}) exited unexpectedly') from e
RuntimeError: DataLoader worker (pid(s) 78443) exited unexpectedly
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 212, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 176, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1018, in _run_stage
    return self._evaluation_loop.run()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py", line 178, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 319, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 411, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
  File "/home/ec2-user/workspace/cf_rank/engine.py", line 250, in validation_step
    out_dict, labels = self.common_step(batch, batch_idx)
  File "/home/ec2-user/workspace/cf_rank/engine.py", line 114, in common_step
    examination = infer_ultr(pos_idx=pos_idx, device=self.device)
  File "/home/ec2-user/workspace/cf_rank/src/ultr_models.py", line 24, in infer_ultr
    propensities = torch.tensor(df.iloc[:, 1].values).to(device)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 67, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 78258) is killed by signal: Killed. 
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1131, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/multiprocessing/queues.py", line 114, in get
    raise Empty
_queue.Empty

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 212, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 176, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1018, in _run_stage
    return self._evaluation_loop.run()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py", line 178, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 128, in run
    batch, batch_idx, dataloader_idx = next(data_fetcher)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/fetchers.py", line 133, in __next__
    batch = super().__next__()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/fetchers.py", line 60, in __next__
    batch = next(self.iterator)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/utilities/combined_loader.py", line 341, in __next__
    out = next(self._iterator)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/utilities/combined_loader.py", line 142, in __next__
    out = next(self.iterators[0])
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
    data = self._next_data()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1327, in _next_data
    idx, data = self._get_data()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1293, in _get_data
    success, data = self._try_get_data()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1144, in _try_get_data
    raise RuntimeError(f'DataLoader worker (pid(s) {pids_str}) exited unexpectedly') from e
RuntimeError: DataLoader worker (pid(s) 77925, 77926, 77927, 77928) exited unexpectedly
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 212, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 176, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1018, in _run_stage
    return self._evaluation_loop.run()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py", line 178, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 319, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 411, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
  File "/home/ec2-user/workspace/cf_rank/engine.py", line 250, in validation_step
    out_dict, labels = self.common_step(batch, batch_idx)
  File "/home/ec2-user/workspace/cf_rank/engine.py", line 113, in common_step
    pos_idx[i][0:n] = sample_swap(pos=pos_idx[i][0:n].float(), click=[examination[i][0:n], relevance[i][0:n]], fn=self.args.sampling_type, ultr_mod=True)
  File "/home/ec2-user/workspace/cf_rank/src/utils.py", line 207, in sample_swap
    swap_idx = torch.multinomial(pos, 1)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 67, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 77663) is killed by signal: Killed. 
ERROR:root:An error occurred:
Traceback (most recent call last):
  File "/home/ec2-user/workspace/cf_rank/main.py", line 212, in <module>
    main(args)
  File "/home/ec2-user/workspace/cf_rank/main.py", line 176, in main
    pyl_trainer.validate(trainer,test_dataloader)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 639, in validate
    return call._call_and_handle_interrupt(
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 47, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 679, in _validate_impl
    results = self._run(model, ckpt_path=ckpt_path)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 981, in _run
    results = self._run_stage()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1018, in _run_stage
    return self._evaluation_loop.run()
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py", line 178, in _decorator
    return loop_run(self, *args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 319, in _call_strategy_hook
    output = fn(*args, **kwargs)
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/pytorch_lightning/strategies/strategy.py", line 411, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
  File "/home/ec2-user/workspace/cf_rank/engine.py", line 250, in validation_step
    out_dict, labels = self.common_step(batch, batch_idx)
  File "/home/ec2-user/workspace/cf_rank/engine.py", line 111, in common_step
    pos_idx[i][0:n] = sample_perturb(delta=self.args.delta_retain, pos=pos_idx[i][0:n].float())
  File "/home/ec2-user/workspace/cf_rank/src/utils.py", line 168, in sample_without_replacement_with_prob
    if weights.sum() == 0:
  File "/home/ec2-user/anaconda3/envs/rank3/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 67, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 77467) is killed by signal: Killed. 
