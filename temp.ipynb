{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000e-12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(2,9,786).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 9, 786])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "ln = nn.LayerNorm(786, eps=1e-12).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = ln(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 9, 786])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.tensor([1,1,0])\n",
    "b = torch.tensor([0.5,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(b-a, torch.tensor ([0.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1, -1,  1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.full([2, 5], 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5000, 1.5000, 1.5000, 1.5000, 1.5000],\n",
       "        [1.5000, 1.5000, 1.5000, 1.5000, 1.5000]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ggbhatt/anaconda3/envs/rank1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ggbhatt/anaconda3/envs/rank1/lib/python3.9/site-packages/datasets/load.py:1486: FutureWarning: The repository for philipphager/baidu-ultr_baidu-mlm-ctr contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/philipphager/baidu-ultr_baidu-mlm-ctr\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"philipphager/baidu-ultr_baidu-mlm-ctr\",name=\"clicks\",\n",
    "                            split=\"train\", # [\"train\", \"test\"]\n",
    "                            cache_dir=\"~/.cache/huggingface\",\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['query_id', 'query_md5', 'query', 'query_length', 'n', 'url_md5', 'text_md5', 'title', 'abstract', 'query_document_embedding', 'click', 'position', 'media_type', 'displayed_time', 'serp_height', 'slipoff_count_after_click', 'bm25', 'bm25_title', 'bm25_abstract', 'tf_idf', 'tf', 'idf', 'ql_jelinek_mercer_short', 'ql_jelinek_mercer_long', 'ql_dirichlet', 'document_length', 'title_length', 'abstract_length'],\n",
       "    num_rows: 1779017\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[37.58316421508789,\n",
       " 36.20572280883789,\n",
       " 56.07870864868164,\n",
       " 70.85820007324219,\n",
       " 52.38069152832031,\n",
       " 47.444210052490234,\n",
       " 51.77769088745117,\n",
       " 41.325138092041016]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['bm25'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25.439960479736328,\n",
       " 20.177860260009766,\n",
       " 41.639854431152344,\n",
       " 35.50246810913086,\n",
       " 38.605186462402344,\n",
       " 25.439960479736328,\n",
       " 39.025325775146484,\n",
       " 22.449565887451172]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['tf_idf'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ggbhatt/anaconda3/envs/rank1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Jax plugin configuration error: Exception when calling jax_plugins.xla_cuda12.initialize()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ggbhatt/anaconda3/envs/rank1/lib/python3.9/site-packages/jax/_src/xla_bridge.py\", line 430, in discover_pjrt_plugins\n",
      "    plugin_module.initialize()\n",
      "  File \"/home/ggbhatt/anaconda3/envs/rank1/lib/python3.9/site-packages/jax_plugins/xla_cuda12/__init__.py\", line 78, in initialize\n",
      "    options = xla_client.generate_pjrt_gpu_plugin_options()\n",
      "AttributeError: module 'jaxlib.xla_client' has no attribute 'generate_pjrt_gpu_plugin_options'\n",
      "/home/ggbhatt/anaconda3/envs/rank1/lib/python3.9/site-packages/datasets/load.py:1486: FutureWarning: The repository for philipphager/baidu-ultr_baidu-mlm-ctr contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/philipphager/baidu-ultr_baidu-mlm-ctr\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.bert import BertModel, BertReward\n",
    "from transformers.models.bert.configuration_bert import BertConfig\n",
    "\n",
    "config = BertConfig()\n",
    "\n",
    "config.vocab = 100\n",
    "config.num_labels = 1 # regression output\n",
    "config.problem_type = \"classification\"\n",
    "config.max_position_embeddings = 50\n",
    "\n",
    "# if args.use_doc_feat:\n",
    "# \t# self.config.doc_feat_len=0\n",
    "# \tself.config.hidden_size+=12\n",
    "\n",
    "reward_model = BertReward(config)\n",
    "\n",
    "mname = \"dfeat_un\"\n",
    "checkpoint = torch.load('../outputs/'+mname+'/checkpoint35.pth', map_location='cpu')\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "train_dataset = load_dataset(\"philipphager/baidu-ultr_baidu-mlm-ctr\",name=\"clicks\",\n",
    "                            split=\"train\", # [\"train\", \"test\"]\n",
    "                            cache_dir=\"~/.cache/huggingface\",\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import collate_fn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = load_dataset(\"philipphager/baidu-ultr_baidu-mlm-ctr\",name=\"clicks\",\n",
    "                        split=\"train\", # [\"train\", \"test\"]\n",
    "                        cache_dir=\"~/.cache/huggingface\",\n",
    "                        )\n",
    "\n",
    "test_dataset = load_dataset(\"philipphager/baidu-ultr_baidu-mlm-ctr\",name=\"clicks\",\n",
    "                        split=\"test\", # [\"train\", \"test\"]\n",
    "                        cache_dir=\"~/.cache/huggingface\",\n",
    "                        )\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, collate_fn=collate_fn, batch_size=64,\n",
    "                                num_workers=2, pin_memory=True)\n",
    "    \n",
    "test_dataloader = DataLoader(test_dataset, collate_fn=collate_fn, batch_size=64,\n",
    "                                num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/ggbhatt/workspace/cf_ranking/cf_rank/src/data.py:71: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400412039/work/torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  column: torch.tensor(features, dtype=COLUMNS[column][\"dtype\"])\n",
      "/local/home/ggbhatt/workspace/cf_ranking/cf_rank/src/data.py:71: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1702400412039/work/torch/csrc/utils/tensor_new.cpp:261.)\n",
      "  column: torch.tensor(features, dtype=COLUMNS[column][\"dtype\"])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for batch in iter(train_dataloader):\n",
    "    feat = batch['query_document_embedding']\n",
    "    pos_idx = batch['position']\n",
    "    out = reward_model(inputs_embeds=feat, position_ids=pos_idx)\n",
    "    bre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfeat\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feat' is not defined"
     ]
    }
   ],
   "source": [
    "feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['n', 'query_document_embedding', 'click', 'position', 'bm25', 'bm25_title', 'bm25_abstract', 'tf_idf', 'tf', 'idf', 'ql_jelinek_mercer_short', 'ql_jelinek_mercer_long', 'ql_dirichlet', 'document_length', 'title_length', 'abstract_length', 'mask'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.tensor([1,2,3]),os.path.join('__pycache__','def'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rank1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
